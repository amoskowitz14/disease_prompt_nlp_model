{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Classification_Example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LzbGMe24AG7",
        "colab_type": "text"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T8aBfwY384K",
        "colab_type": "text"
      },
      "source": [
        "### Overview:\n",
        "With the arrival of [new medical documentation in the US](https://www.healthcareitnews.com/news/how-sdoh-will-influence-next-wave-health-tech-startups) it is possible to build a model that can classify symptom names based upon input text from patients describing their illness.\n",
        "\n",
        "Utilized Keras to generate a Convolutional Neural Network (CNN) and dense neural network with a 200 dimensional Genism Word2Vec embedding and 6,650 records of patient condition descriptions to predict symptoms with a close to 100% test accuracy from both models.\n",
        "\n",
        "### SetUp:\n",
        "1. Install all packages from the Import statement.\n",
        "2. The 200 dimensional Word2Vec file of glove.6B.200d.txt can be downloaded at a zip file [here](http://nlp.stanford.edu/data/glove.6B.zip) (822 MB). See main page at the [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/) introduction page.\n",
        "3. Designate the file path of the input data and Gensim embedding file as a string in the 'directory' object.\n",
        "4. Download data file from github [here](https://github.com/amoskowitz14/disease_prompt_nlp_model/blob/master/phrase_disease_data.csv)\n",
        "\n",
        "### Sources:\n",
        "1. [Word Embedding use in Keras](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/)\n",
        "\n",
        "2. [Original Data Source from Figure Eight](https://www.figure-eight.com/dataset/audio-recording-and-transcription-for-medical-scenarios/)\n",
        "\n",
        "3. [Convolutional Neural Networks in Keras](https://realpython.com/python-keras-text-classification/#convolutional-neural-networks-cnn)\n",
        "\n",
        "### Author:\n",
        "[Aaron Moskowitz](https://www.linkedin.com/in/aaroncmoskowitz/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmWSj73D07ZI",
        "colab_type": "text"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaCxoR5bc4VV",
        "colab_type": "code",
        "outputId": "126cdc9c-f2bd-474c-cfa4-700bd5ed470f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Directory Configuration\n",
        "import os\n",
        "\n",
        "# Goolge Colab Setup\n",
        "from google.colab import drive\n",
        "\n",
        "# Object Manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Word2Vec Import\n",
        "import gensim\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "# Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Embedding Creation\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "# Keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Activation, Dense, Embedding, Flatten\n",
        "\n",
        "# Test Train Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Visulization\n",
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1srwJoSUZlAH",
        "colab_type": "text"
      },
      "source": [
        "# Setup of project directory, or use of google Colab to run code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DsOxYfQ0-73",
        "colab_type": "code",
        "outputId": "5c527e2a-7bb3-4ac3-93e4-fabcefe8dc7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CthicZvj1TB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory = \"/content/drive/My Drive/Colab Notebooks/Deep_Learning_NLP/Keras_Healthcare_NLP_Project\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXAu6PMU2FNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdDyStDX1OWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_file = datapath(directory + '/glove/glove.6B.200d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbYhSW2d086-",
        "colab_type": "text"
      },
      "source": [
        "# Load Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlPYzI3FY4Ts",
        "colab_type": "text"
      },
      "source": [
        "### Load the whole 200 dimensional embedding into memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5NYP0r0bWMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = dict()\n",
        "\n",
        "f = open(datapath(glove_file))\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phs9pIsFZSS0",
        "colab_type": "text"
      },
      "source": [
        "### Confirm Gensin embedding is expected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUHeeQaaZPUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fee8efd-8541-4c8e-8871-48bf6c3c2d78"
      },
      "source": [
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAshhO5lbhg_",
        "colab_type": "code",
        "outputId": "00703f56-240b-4bda-c717-fafb65488495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('''Confirm the embedding of a relevant word such as 'head' with its embedding size of''', len(embeddings_index['head']), 'is expected.')\n",
        "print('View first 5 ellements of the embedding to see if it is plausible. First ellements are', embeddings_index['head'][0:5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confirm the embedding of a relevant word such as 'head' with its embedding size of 200 is expected.\n",
            "View first 5 ellements of the embedding to see if it is plausible. First ellements are [-0.26623  -0.75065  -0.031357 -0.03684  -0.1875  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU0jCABS42XH",
        "colab_type": "text"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY2BM-XTch11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85bac5ad-48ec-4a41-a834-e7ced9db8ee9"
      },
      "source": [
        "# Load data from csv\n",
        "input_data = pd.read_csv(directory + '/data/phrase_disease_data.csv') \n",
        "\n",
        "# 5th and 6thh column have phrase and prompt respectively\n",
        "col = ['phrase', 'prompt']\n",
        "input_data = input_data[col]\n",
        "\n",
        "# Get phrases into a series\n",
        "phrases = input_data['phrase']\n",
        "prompts = input_data['prompt']\n",
        "\n",
        "print('Data import has rows of:', len(input_data))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data import has rows of: 6650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNmoTVZKoCpc",
        "colab_type": "text"
      },
      "source": [
        "### View 5 example phrases and associated prompts in data to confirm upload worked as expected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7VEMhZfl12c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "95089d0f-edc9-4eec-fc50-0e77d6bc9633"
      },
      "source": [
        "phrases.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                      When I remember her I feel down\n",
              "1    When I carry heavy things I feel like breaking...\n",
              "2            there is too much pain when i move my arm\n",
              "3    My son had his lip pierced and it is swollen a...\n",
              "4               My muscles in my lower back are aching\n",
              "Name: phrase, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGHyeCdRoH77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a84c3a32-6671-451c-aa46-5ef1c9884b0a"
      },
      "source": [
        "prompts.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Emotional pain\n",
              "1    Hair falling out\n",
              "2         Heart hurts\n",
              "3      Infected wound\n",
              "4      Infected wound\n",
              "Name: prompt, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhd3EGPKoXTD",
        "colab_type": "text"
      },
      "source": [
        "# Create One Hot Encoding and Dictionary for Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKrNOt7QoxNd",
        "colab_type": "text"
      },
      "source": [
        "## Create integer dictionary for pompts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXZAq1l2uF17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get prompt and replace space with underscore\n",
        "prompt = [word.replace(\" \",\"_\").lower() for word in prompts]\n",
        "\n",
        "# Adding a column of category_id encoding the prompt as an integer to ease in represenation of class\n",
        "input_data['category_id'] = prompts.factorize()[0]\n",
        "category_id_df = input_data[['prompt', 'category_id']].drop_duplicates().sort_values('category_id')\n",
        "\n",
        "# Generate dictionary to code categorical_id back to prompt\n",
        "category_to_id = dict(category_id_df.values)\n",
        "id_to_category = dict(category_id_df[['category_id', 'prompt']].values)\n",
        "\n",
        "# Converting promopts to a list of integers\n",
        "prompt = list(input_data['category_id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_ebSnwKo9UQ",
        "colab_type": "text"
      },
      "source": [
        "### View prompt_id to prompt dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4GeAsNUPTu4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "3f09c373-6c8b-46a2-85e6-837f75b77c99"
      },
      "source": [
        "print('The size of the dictionary is', len(set(prompt)))\n",
        "\n",
        "print('\\nView entire dictionary:')\n",
        "id_to_category"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the dictionary is 25\n",
            "\n",
            "View entire dictionary:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Emotional pain',\n",
              " 1: 'Hair falling out',\n",
              " 2: 'Heart hurts',\n",
              " 3: 'Infected wound',\n",
              " 4: 'Foot ache',\n",
              " 5: 'Shoulder pain',\n",
              " 6: 'Injury from sports',\n",
              " 7: 'Skin issue',\n",
              " 8: 'Stomach ache',\n",
              " 9: 'Knee pain',\n",
              " 10: 'Joint pain',\n",
              " 11: 'Hard to breath',\n",
              " 12: 'Head ache',\n",
              " 13: 'Body feels weak',\n",
              " 14: 'Feeling dizzy',\n",
              " 15: 'Back pain',\n",
              " 16: 'Open wound',\n",
              " 17: 'Internal pain',\n",
              " 18: 'Blurry vision',\n",
              " 19: 'Acne',\n",
              " 20: 'Muscle pain',\n",
              " 21: 'Neck pain',\n",
              " 22: 'Cough',\n",
              " 23: 'Ear ache',\n",
              " 24: 'Feeling cold'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0gdh5awQRLT",
        "colab_type": "text"
      },
      "source": [
        "## Create one hot encoding representation of prompt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lP2yrn09VVc",
        "colab_type": "code",
        "outputId": "cea6fba5-4800-4842-99e2-2c9dee24649a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prompt[0:5]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfg7OC-8-nbV",
        "colab_type": "code",
        "outputId": "80c5bef2-ed95-49d7-bdfc-b713cdd9f54d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prompt_length = len(np.array(prompt))\n",
        "class_len = len(set(prompt))\n",
        "print('Confirm prompt length is unchanged:', class_len)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confirm prompt length is unchanged: 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c46YV73g-YsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prompt_length = len(np.array(prompt))\n",
        "\n",
        "empty_array = np.zeros((prompt_length, class_len))\n",
        "empty_array[np.arange(prompt_length), prompt] = 1\n",
        "prompt_one_hot = empty_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9f6xeBQ_3H_",
        "colab_type": "code",
        "outputId": "e5456881-ad59-4ee0-9734-ebcdc2301109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "prompt_one_hot"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ico5L3Y9CSte",
        "colab_type": "code",
        "outputId": "164a6dac-f8dd-4ff3-f68b-aa590237d0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Confirm that all records are covered in one hot encoding:', len(prompt_one_hot))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confirm that all records are covered in one hot encoding: 6650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUTaqoF5EJ9a",
        "colab_type": "text"
      },
      "source": [
        "# Prepare data features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0c0MveifoBh",
        "colab_type": "code",
        "outputId": "eeb56eb9-fc19-4a24-cdea-fdb25aff3a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# prepare tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(phrases.tolist())\n",
        "vocab_size = len(t.word_index) + 1\n",
        "\n",
        "# integer encode the documents\n",
        "encoded_docs = t.texts_to_sequences(phrases.tolist())\n",
        "print(encoded_docs[0:5])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10, 1, 583, 125, 1, 7, 77], [10, 1, 261, 99, 185, 1, 7, 18, 416, 2, 23], [35, 11, 91, 94, 6, 10, 1, 106, 2, 98], [2, 189, 52, 167, 301, 439, 8, 13, 11, 179, 8, 9, 40, 89, 15, 167, 301, 11, 584, 8, 190, 83], [2, 145, 4, 2, 136, 23, 73, 224]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bddUbJI6hgxV",
        "colab_type": "code",
        "outputId": "b9c262f2-0cc4-4f8b-f020-1dfcb727996b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('The training data phrase word count is the covabulary size of', vocab_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training data phrase word count is the covabulary size of 1160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqKrWmj3gJ0U",
        "colab_type": "code",
        "outputId": "e2dbad0f-1f1c-4e33-fea0-9b84ca11df62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# pad documents to a max length of the longest word\n",
        "max_length = 0\n",
        "for doc in encoded_docs:\n",
        "  if len(doc) > max_length:\n",
        "    max_length = len(doc)\n",
        "\n",
        "print('The training data with the longest word length is', max_length)\n",
        "\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training data with the longest word length is 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VXepMS2g9iT",
        "colab_type": "code",
        "outputId": "7f646421-3bfe-427a-d5df-754abe1d664e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Confirm that the padded_docs has the correct size of', len(padded_docs))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confirm that the padded_docs has the correct size of 6650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od_SqJnLWiV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c90aef6d-1e60-4eee-f03e-60047cc82048"
      },
      "source": [
        "print('Confirm that the phrase below has the same number of non zero tokens in the padded document', phrases[1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confirm that the phrase below has the same number of non zero tokens in the padded document When I carry heavy things I feel like breaking my back\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9teBAYeCN46",
        "colab_type": "code",
        "outputId": "01764b43-6623-4aa8-ba65-7772076cfaeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('See padded document for the position 1 phrase', padded_docs[1])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "See padded document for the position 1 phrase [ 10   1 261  99 185   1   7  18 416   2  23   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZrMQKZHwg1u",
        "colab_type": "text"
      },
      "source": [
        "### Add an index in front of each padded phrase to allow tracking of the true prompt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gHRBSHScjPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "af9d4029-e3bf-490a-8642-b12bdf0f7939"
      },
      "source": [
        "indexed_padded_docs = list()\n",
        "\n",
        "counter = 0\n",
        "for row in padded_docs:\n",
        "  indexed_padded_docs.append(list((counter, row)))\n",
        "  counter = counter + 1\n",
        "\n",
        "indexed_padded_docs = np.array(indexed_padded_docs)\n",
        "\n",
        "print(type(indexed_padded_docs))\n",
        "print(len(indexed_padded_docs))\n",
        "print(indexed_padded_docs[0:4])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "6650\n",
            "[[0\n",
            "  array([ 10,   1, 583, 125,   1,   7,  77,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0], dtype=int32)]\n",
            " [1\n",
            "  array([ 10,   1, 261,  99, 185,   1,   7,  18, 416,   2,  23,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0], dtype=int32)]\n",
            " [2\n",
            "  array([ 35,  11,  91,  94,   6,  10,   1, 106,   2,  98,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0], dtype=int32)]\n",
            " [3\n",
            "  array([  2, 189,  52, 167, 301, 439,   8,  13,  11, 179,   8,   9,  40,\n",
            "        89,  15, 167, 301,  11, 584,   8, 190,  83,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0], dtype=int32)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbsOPtepbJHr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64f0d2cb-c36f-42e1-e3f8-7d802fb9a6de"
      },
      "source": [
        "len(padded_docs)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6650"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u89jEoqlh0WX",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Weights for Data from Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlGnjmwGi7y8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = zeros((vocab_size, 200))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHX29effgjo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "23e8f9c7-379f-42b4-8d41-34eba79d0f2f"
      },
      "source": [
        "embedding_matrix"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.26804999,  0.36032   , -0.33199999, ...,  0.17769   ,\n",
              "         0.22362   ,  0.014241  ],\n",
              "       [ 0.30379999,  0.18126   ,  0.46583   , ...,  0.29550999,\n",
              "        -0.25325999,  0.72632998],\n",
              "       ...,\n",
              "       [ 0.077027  , -0.25341001, -0.15026   , ...,  0.2938    ,\n",
              "        -0.23005   , -0.17716999],\n",
              "       [ 0.29876   , -0.14601   , -0.15304001, ...,  0.28331   ,\n",
              "        -0.11579   ,  0.92505997],\n",
              "       [ 0.55844998,  0.66096002,  0.32642999, ...,  0.17189001,\n",
              "         0.050269  , -0.42519999]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgoJER92jLzm",
        "colab_type": "code",
        "outputId": "741af83b-493d-4d0f-b5b6-8faf00df0399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(embedding_matrix)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnF6budHrYp_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "160d73d7-e4d2-4f67-9bff-6e42a70c349f"
      },
      "source": [
        "np.shape(embedding_matrix)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1160, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY2v7XexrL15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21900448-da02-4a38-ad14-1835e907ab5a"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1160"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjzMj_rMFzYz",
        "colab_type": "text"
      },
      "source": [
        "# Test Train Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yp3wSbJB-ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the data into training and validation set with 80%, 20% respectively\n",
        "train_x, test_x, train_y, test_y = train_test_split(indexed_padded_docs ,prompt_one_hot, test_size=0.2, random_state=1,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1QwI47ww8fK",
        "colab_type": "text"
      },
      "source": [
        "### Confirm that sizes of features and target in both the train and test are the same, and view sample of train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcoiyR0KCbR-",
        "colab_type": "code",
        "outputId": "6734b1c3-86d3-47f1-dd49-03e5a1475d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(len(train_x))\n",
        "print(len(train_y))\n",
        "print(len(test_x))\n",
        "print(len(test_y))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5320\n",
            "5320\n",
            "1330\n",
            "1330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27mlFwKhhlQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "5c573561-b1cf-49ce-c579-be4fa06da543"
      },
      "source": [
        "train_x[0:5]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[102,\n",
              "        array([  1,   5,  36,  48,  41,  22, 257,  79, 188,   1, 110,   5,   3,\n",
              "        33,  53, 218,  53, 139, 342, 445, 113,  36, 963,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=int32)],\n",
              "       [589,\n",
              "        array([ 35,  11,   3,  50,   6,   4,   2, 744,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=int32)],\n",
              "       [5323,\n",
              "        array([ 1, 75,  2, 55, 11, 83,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)],\n",
              "       [1558,\n",
              "        array([ 10,   1,  26, 966,   2,  28,  13,  26,  95,  30, 967,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=int32)],\n",
              "       [1228,\n",
              "        array([ 25, 309,   1,   5, 173,  93,  89,  14,  24,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=int32)]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1KOLbRnPMtm",
        "colab_type": "text"
      },
      "source": [
        "### Create helper function to convert indexed array to non-indexed array for use in training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyNKsmNZiTZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "efefdb59-99a6-4ef9-f415-03d39c9ed397"
      },
      "source": [
        "def to_non_indexed_array(indexed_array):\n",
        "   \n",
        "  non_indexed_list = list()\n",
        "\n",
        "  counter = 0\n",
        "  for row in indexed_array:\n",
        "\n",
        "    non_indexed_list.append(row[1])\n",
        "    counter = counter + 1\n",
        "\n",
        "  non_indexed_array = np.array(non_indexed_list)\n",
        "  \n",
        "  return(non_indexed_array)\n",
        "\n",
        "to_non_indexed_array(test_x)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1,  86, 260, ...,   0,   0,   0],\n",
              "       [ 25, 111, 112, ...,   0,   0,   0],\n",
              "       [  2, 759,  37, ..., 585,  21, 761],\n",
              "       ...,\n",
              "       [  1,   5, 105, ...,   0,   0,   0],\n",
              "       [  2, 845,   8, ...,   0,   0,   0],\n",
              "       [  2,  38,  37, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR6WhT8Exfu2",
        "colab_type": "text"
      },
      "source": [
        "# Create Dense Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLVZAqhgi3Ez",
        "colab_type": "code",
        "outputId": "89cdb810-f11e-4eeb-cb6a-8a722743fca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "# Define model\n",
        "model_dense = Sequential()\n",
        "\n",
        "# Embedding Layers\n",
        "e = Embedding(vocab_size, 200, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
        "model_dense.add(e)\n",
        "model_dense.add(Flatten())\n",
        "\n",
        "# Dense layer\n",
        "model_dense.add(Dense(len(set(prompt))))\n",
        "\n",
        "# Output Layer\n",
        "model_dense.add(Activation('softmax'))\n",
        "\n",
        "# Compile Model\n",
        "model_dense.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summarize Model\n",
        "print(model_dense.summary())\n",
        "\n",
        "# Fit Model\n",
        "model_dense.fit(to_non_indexed_array(train_x), train_y, epochs=3, verbose=0)\n",
        "\n",
        "# Evaluate Model\n",
        "loss, accuracy = model_dense.evaluate(to_non_indexed_array(test_x), test_y, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 30, 200)           232000    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6000)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 25)                150025    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 25)                0         \n",
            "=================================================================\n",
            "Total params: 382,025\n",
            "Trainable params: 150,025\n",
            "Non-trainable params: 232,000\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Accuracy: 99.248120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hVaLdTCOWPB",
        "colab_type": "text"
      },
      "source": [
        "# Create Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li-2AGMNiwKo",
        "colab_type": "code",
        "outputId": "da14a6ce-9b9a-4382-9272-77876457454f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "cnn_model = Sequential()\n",
        "\n",
        "# Embedding Layer\n",
        "e = Embedding(vocab_size, 200, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
        "cnn_model.add(e)\n",
        "\n",
        "# Convolutional and Max Pooling Layer\n",
        "cnn_model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "cnn_model.add(layers.GlobalMaxPooling1D())\n",
        "\n",
        "# Dense Layer\n",
        "cnn_model.add(layers.Dense(10, activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "cnn_model.add(layers.Dense(len(set(prompt)), activation='sigmoid'))\n",
        "cnn_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Summarize Model\n",
        "cnn_model.summary()\n",
        "\n",
        "# Fit Model\n",
        "history = cnn_model.fit(to_non_indexed_array(train_x),train_y,\n",
        "                    epochs=3,\n",
        "                    verbose=1)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 30, 200)           232000    \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 26, 128)           128128    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_7 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 25)                275       \n",
            "=================================================================\n",
            "Total params: 361,693\n",
            "Trainable params: 129,693\n",
            "Non-trainable params: 232,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "5320/5320 [==============================] - 2s 331us/step - loss: 0.1990 - acc: 0.9391\n",
            "Epoch 2/3\n",
            "5320/5320 [==============================] - 1s 215us/step - loss: 0.0785 - acc: 0.9727\n",
            "Epoch 3/3\n",
            "5320/5320 [==============================] - 1s 206us/step - loss: 0.0375 - acc: 0.9900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txNqAj7ty5aA",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCktUQ3gvITW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a8cc87d9-376b-4863-da05-0304a2420da9"
      },
      "source": [
        "#History Object Preserves Training Accuracy\n",
        "loss = history.history['acc']\n",
        "\n",
        "#Number of Epochs\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot Training Accuracy\n",
        "plt.plot(epochs, loss, 'bo', label='Training Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEJCAYAAAB4yveGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XncQ15FFxapa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76decbcb-025d-41bb-b56b-8094d7014267"
      },
      "source": [
        "# evaluate the model\n",
        "loss, accuracy = cnn_model.evaluate(to_non_indexed_array(test_x), test_y, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.371429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AoxqYegBklk",
        "colab_type": "text"
      },
      "source": [
        "# Exploration of Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXiAthW6HzTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exploration_output(model_exploration, num, verbose = True):\n",
        "  '''Parameters: model_exploration - type: keras.engine.sequential.Sequential\n",
        "    num - type: integer - Element in the test set to view the actual class and scores of predicted classes\n",
        "    verbose - type: boolean - If True, prints details out phrase of the num element in the test set, and the true class of the element.\n",
        "    Output: Descending dataframe of most probable classes ordered by softmax scoring\n",
        "  '''\n",
        "  if verbose:\n",
        "    print('Testing output from phrase of:', phrases[test_x[num][0]])\n",
        "\n",
        "  model_exploration.predict(to_non_indexed_array(test_x), verbose=0)[num]\n",
        "\n",
        "  results = pd.DataFrame(columns=['Class Id', 'Prompt', 'Score'])\n",
        "  results = list()\n",
        "  index = 0\n",
        "  for score in model_exploration.predict(to_non_indexed_array(test_x), verbose=0)[num]:\n",
        "    row = list((index, id_to_category.get(index), score))\n",
        "    results.append(row)\n",
        "    index = index + 1\n",
        "\n",
        "  results = pd.DataFrame(columns=['Class Id', 'Prompt', 'Score'], data = results)\n",
        "  \n",
        "  if verbose:\n",
        "    print('True class is:', id_to_category.get(np.argmax(test_y[num])))\n",
        "    \n",
        "  return(results.sort_values(by='Score', ascending = False).head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WFySu1rx3YL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "59900801-6aa7-47c2-ad8b-cd3fad310368"
      },
      "source": [
        "exploration_output(model_dense, 5)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing output from phrase of: I feel a pain on the left side of my chest, where my heart is\n",
            "True class is: Heart hurts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Id</th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Heart hurts</td>\n",
              "      <td>0.913194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Foot ache</td>\n",
              "      <td>0.025469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Shoulder pain</td>\n",
              "      <td>0.012864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>Head ache</td>\n",
              "      <td>0.009703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>Joint pain</td>\n",
              "      <td>0.008669</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Class Id         Prompt     Score\n",
              "2          2    Heart hurts  0.913194\n",
              "4          4      Foot ache  0.025469\n",
              "5          5  Shoulder pain  0.012864\n",
              "12        12      Head ache  0.009703\n",
              "10        10     Joint pain  0.008669"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Jn2o_yHsOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "68dd9d8c-40c8-40cb-8508-14120fa344d2"
      },
      "source": [
        "exploration_output(cnn_model, 5)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing output from phrase of: I feel a pain on the left side of my chest, where my heart is\n",
            "True class is: Heart hurts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Id</th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Heart hurts</td>\n",
              "      <td>0.810164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Infected wound</td>\n",
              "      <td>0.039408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>Back pain</td>\n",
              "      <td>0.033659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Knee pain</td>\n",
              "      <td>0.030153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>Head ache</td>\n",
              "      <td>0.015866</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Class Id          Prompt     Score\n",
              "2          2     Heart hurts  0.810164\n",
              "3          3  Infected wound  0.039408\n",
              "15        15       Back pain  0.033659\n",
              "9          9       Knee pain  0.030153\n",
              "12        12       Head ache  0.015866"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    }
  ]
}